# Transformer_learning

A simple implementation of Transformer using Pytorch

Much thanks to the repo : [https://github.com/jadore801120/attention-is-all-you-need-pytorch/tree/master](https://github.com/jadore801120/attention-is-all-you-need-pytorch/tree/master) !

It's a clear and detailed implementation, from which I've learnt a lot . And my code is mainly refered to the repo , I added some annotations and renamed some variables to make better understanding.

And also much thanks to [https://github.com/sooftware/attentions](https://github.com/sooftware/attentions)

The repo provides a variety of implementations of attention with different types , I also get inspired a lot !
